{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we want to do some text classification and are just starting out with the project. There are some general steps that we can take to make sure we set up the project for sucess!\n",
    "\n",
    "* Step 1: Get some data\n",
    "* Step 2: Clean and analyze data\n",
    "* Step 3: Choose one or more algorithms\n",
    "* Step 4: Analyze algorithm and choose one for production\n",
    "\n",
    "We'll go over each of these steps in detail in this notebook using the 20 newsgroup dataset that come preinstalled in sklearn. Note too that there may be other steps you need to consider as well in your own projects, but this is a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_recall_fscore_support, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get some Data\n",
    "\n",
    "Get the 20 Newsgroups data is nice bc it is longer text, labeled and just a bit messy\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#newsgroups for more info and some good examples.\n",
    "The first time you run this, the data will be downloaded, but it is fairly small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hey folks--\\n\\nI've got a pair of Dunlop sportmax radials of my ZX-10, and they've been\\nvery sticky (ie no slides yet), but all this talk about the Metzelers has\\nme wondering if my next set should be a Lazer comp K and a radial Metzeler\\nrear...for hard sport-touring, how do the choices stack up?\", \"From article <eabu288-140493210752@dialin33635.slip.nts.uci.edu>, by eabu288@orion.oac.uci.edu (Alvin):\\n\\n--Could be.  Isn't the 2.5 liter six supposed to be enlarged to 2.8 liters\\n  in the not-too-distant future?\\n\\n--Aamir Qazi\\n\\n-- \", '\\n\\nI agree.  Six hour long stretches behind the wheel really make me\\nthirsty, especially for something with caffeine.  I consider it a\\nfailing of my car that it has no cup holder nor anywhere to put a cup\\nholder.']\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'rec.autos',\n",
    "    'rec.motorcycles',\n",
    "    'sci.space'\n",
    "]\n",
    "\n",
    "# Removing the headers, footers and quotes only keeps the line information\n",
    "# The header and footer information in particular have metadata which would cause the algorithm to be overfitted\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Look to see what the first three entries of the raw data looks like\n",
    "print(newsgroups_train.data[:3])\n",
    "print(newsgroups_train.target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean and analyze data\n",
    "\n",
    "### Analyzing any potential dataset biases\n",
    "\n",
    "Now that we have the data we want to make sure that it is balanced. Unbalanced datasets can cause algorithms to be biased - favoring the classification of one class over another. We can count the number of each type of label, or view the labels as a histogram. If the dataset is unbalanced, then remedial measures can be utilized to balance the classes out. Alternatively, many algorithms (including PyTorch) let you give weights to the classes in order to help the algorithm be less biased.\n",
    "\n",
    "A nice feature of the 20 newsgroup dataset is that it is balanced, but it is important to always look at the breakdown of your data before trying to build a classifier for it.\n",
    "\n",
    "When looking at a dataset it is also important to know how the dataset was collected and labeled as this has some very real implications to your final algorithm. For instance, if the space articles were only collected on conversations surrounding studying star formation, the classifier would likely not be able to as accuratly classify articles on Martian exploration. It is very important to make sure that your use case matches the intended/expected use of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([594.,   0.,   0.,   0.,   0., 598.,   0.,   0.,   0., 593.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11825e400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([396.,   0.,   0.,   0.,   0., 398.,   0.,   0.,   0., 394.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE9VJREFUeJzt3X+QXeV93/H3pwhDYrsGzOKqkmzhRG0CnVrQLaWm02LwxIDbCE9DByaNZVcdxS3u2NM0DcQzjdMJU3umCRlPWjKyoRYZlx/BdlFd3IbwYzyuC2TBQoBljAzUKNKgjflhM57Qgr/94z5bX29Wu3d/3F35yfs1c+ee85znnPPdo6PPnn3O/ZGqQpLUr7+w1gVIksbLoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1bt1aFwBw6qmn1ubNm9e6DEn6kfLggw/+SVVNLNTvmAj6zZs3MzU1tdZlSNKPlCT/e5R+Dt1IUucMeknqnEEvSZ0z6CWpcyMHfZLjknw1yRfa/OlJ7k/yRJJbkrymtZ/Q5g+05ZvHU7okaRSLuaL/ELB/aP7jwLVVtQV4HtjR2ncAz1fVTwLXtn6SpDUyUtAn2Qi8G/hUmw9wAXBb67IbuLRNb2vztOUXtv6SpDUw6hX9bwP/Gvh+m38j8EJVvdLmDwIb2vQG4BmAtvzF1l+StAYWDPokfx84UlUPDjfP0bVGWDa83Z1JppJMTU9Pj1SsJGnxRnln7HnAzya5BDgR+IsMrvBPSrKuXbVvBA61/geBTcDBJOuANwDPzd5oVe0CdgFMTk76DeU6Zm2+6r+tyX6f/ti712S/6s+CQV9VVwNXAyQ5H/hXVfXzSX4f+DngZmA7cHtbZU+b/19t+d1VNbYgX6v/hOB/REk/GpbzWTe/Atyc5DeArwLXt/brgd9LcoDBlfzlyytRksar9wvGRQV9Vd0L3NumnwTOmaPPnwKXrUBtkqQV4DtjJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMLBn2SE5M8kOThJI8l+fXW/ukkTyXZ2x5bW3uSfCLJgST7kpw97h9CknR0o3yV4MvABVX1UpLjgS8n+WJb9stVddus/hcDW9rjbwHXtWdJ0hpY8Iq+Bl5qs8e3R82zyjbgxrbefcBJSdYvv1RJ0lKMNEaf5Lgke4EjwJ1VdX9bdE0bnrk2yQmtbQPwzNDqB1ubJGkNjBT0VfVqVW0FNgLnJPlrwNXATwF/EzgF+JXWPXNtYnZDkp1JppJMTU9PL6l4SdLCFvWqm6p6AbgXuKiqDrfhmZeB/wSc07odBDYNrbYRODTHtnZV1WRVTU5MTCypeEnSwkZ51c1EkpPa9I8B7wS+PjPuniTApcCjbZU9wHvbq2/OBV6sqsNjqV6StKBRXnWzHtid5DgGvxhuraovJLk7yQSDoZq9wAda/zuAS4ADwPeA96982ZKkUS0Y9FW1DzhrjvYLjtK/gCuXX5okaSX4zlhJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknq3CjfGXtikgeSPJzksSS/3tpPT3J/kieS3JLkNa39hDZ/oC3fPN4fQZI0n1Gu6F8GLqiqtwFbgYval35/HLi2qrYAzwM7Wv8dwPNV9ZPAta2fJGmNLBj0NfBSmz2+PQq4ALitte8GLm3T29o8bfmFSbJiFUuSFmWkMfokxyXZCxwB7gS+CbxQVa+0LgeBDW16A/AMQFv+IvDGlSxakjS6kYK+ql6tqq3ARuAc4Kfn6tae57p6r9kNSXYmmUoyNT09PWq9kqRFWtSrbqrqBeBe4FzgpCTr2qKNwKE2fRDYBNCWvwF4bo5t7aqqyaqanJiYWFr1kqQFjfKqm4kkJ7XpHwPeCewH7gF+rnXbDtzepve0edryu6vqz1zRS5JWx7qFu7Ae2J3kOAa/GG6tqi8k+Rpwc5LfAL4KXN/6Xw/8XpIDDK7kLx9D3ZKkES0Y9FW1DzhrjvYnGYzXz27/U+CyFalOkrRsvjNWkjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOjfKd8ZuSnJPkv1JHkvyodb+0SR/nGRve1wytM7VSQ4keTzJu8b5A0iS5jfKd8a+AvxSVT2U5PXAg0nubMuurap/P9w5yRkMvif2TOAvA3+Y5K9U1asrWbgkaTQLXtFX1eGqeqhNfxfYD2yYZ5VtwM1V9XJVPQUcYI7vlpUkrY5FjdEn2czgi8Lvb00fTLIvyQ1JTm5tG4BnhlY7yPy/GCRJYzRy0Cd5HfBZ4MNV9R3gOuAngK3AYeA3Z7rOsXrNsb2dSaaSTE1PTy+6cEnSaEYK+iTHMwj5z1TV5wCq6tmqerWqvg98kh8MzxwENg2tvhE4NHubVbWrqiaranJiYmI5P4MkaR6jvOomwPXA/qr6raH29UPd3gM82qb3AJcnOSHJ6cAW4IGVK1mStBijvOrmPOAXgEeS7G1tvwpckWQrg2GZp4FfBKiqx5LcCnyNwSt2rvQVN5K0dhYM+qr6MnOPu98xzzrXANcsoy5J0grxnbGS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUuVG+M3ZTknuS7E/yWJIPtfZTktyZ5In2fHJrT5JPJDmQZF+Ss8f9Q0iSjm6UK/pXgF+qqp8GzgWuTHIGcBVwV1VtAe5q8wAXM/hC8C3ATuC6Fa9akjSyBYO+qg5X1UNt+rvAfmADsA3Y3brtBi5t09uAG2vgPuCkJOtXvHJJ0kgWNUafZDNwFnA/8KaqOgyDXwbAaa3bBuCZodUOtjZJ0hoYOeiTvA74LPDhqvrOfF3naKs5trczyVSSqenp6VHLkCQt0khBn+R4BiH/mar6XGt+dmZIpj0fae0HgU1Dq28EDs3eZlXtqqrJqpqcmJhYav2SpAWM8qqbANcD+6vqt4YW7QG2t+ntwO1D7e9tr745F3hxZohHkrT61o3Q5zzgF4BHkuxtbb8KfAy4NckO4FvAZW3ZHcAlwAHge8D7V7RiSdKiLBj0VfVl5h53B7hwjv4FXLnMuiRJK8R3xkpS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnRvnO2BuSHEny6FDbR5P8cZK97XHJ0LKrkxxI8niSd42rcEnSaEa5ov80cNEc7ddW1db2uAMgyRnA5cCZbZ3/mOS4lSpWkrR4CwZ9VX0JeG7E7W0Dbq6ql6vqKQZfEH7OMuqTJC3TcsboP5hkXxvaObm1bQCeGepzsLVJktbIUoP+OuAngK3AYeA3W3vm6FtzbSDJziRTSaamp6eXWIYkaSFLCvqqeraqXq2q7wOf5AfDMweBTUNdNwKHjrKNXVU1WVWTExMTSylDkjSCJQV9kvVDs+8BZl6Rswe4PMkJSU4HtgAPLK9ESdJyrFuoQ5KbgPOBU5McBH4NOD/JVgbDMk8DvwhQVY8luRX4GvAKcGVVvTqe0iVJo1gw6Kvqijmar5+n/zXANcspSpK0cnxnrCR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHVuwaBPckOSI0keHWo7JcmdSZ5ozye39iT5RJIDSfYlOXucxUuSFjbKFf2ngYtmtV0F3FVVW4C72jzAxQy+EHwLsBO4bmXKlCQt1YJBX1VfAp6b1bwN2N2mdwOXDrXfWAP3ASclWb9SxUqSFm+pY/RvqqrDAO35tNa+AXhmqN/B1iZJWiMrfTM2c7TVnB2TnUmmkkxNT0+vcBmSpBlLDfpnZ4Zk2vOR1n4Q2DTUbyNwaK4NVNWuqpqsqsmJiYklliFJWshSg34PsL1NbwduH2p/b3v1zbnAizNDPJKktbFuoQ5JbgLOB05NchD4NeBjwK1JdgDfAi5r3e8ALgEOAN8D3j+GmiVJi7Bg0FfVFUdZdOEcfQu4crlFSZJWju+MlaTOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4t+A1T80nyNPBd4FXglaqaTHIKcAuwGXga+EdV9fzyypQkLdVKXNG/o6q2VtVkm78KuKuqtgB3tXlJ0hoZx9DNNmB3m94NXDqGfUiSRrTcoC/gD5I8mGRna3tTVR0GaM+nLXMfkqRlWNYYPXBeVR1KchpwZ5Kvj7pi+8WwE+DNb37zMsuQJB3Nsq7oq+pQez4CfB44B3g2yXqA9nzkKOvuqqrJqpqcmJhYThmSpHksOeiTvDbJ62emgZ8BHgX2ANtbt+3A7cstUpK0dMsZunkT8PkkM9v5z1X135P8EXBrkh3At4DLll+mJGmplhz0VfUk8LY52r8NXLicoiRJK8d3xkpS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1Lnxhb0SS5K8niSA0muGtd+JEnzG0vQJzkO+A/AxcAZwBVJzhjHviRJ8xvXFf05wIGqerKq/g9wM7BtTPuSJM1jXEG/AXhmaP5ga5MkrbJ1Y9pu5mirH+qQ7AR2ttmXkjy+xH2dCvzJEtddlnx83sVrVtcIjtXarGvIAucXeLwW65isKx9fVl1vGaXTuIL+ILBpaH4jcGi4Q1XtAnYtd0dJpqpqcrnbWWnHal1w7NZmXYtjXYvz57mucQ3d/BGwJcnpSV4DXA7sGdO+JEnzGMsVfVW9kuSDwP8AjgNuqKrHxrEvSdL8xjV0Q1XdAdwxru0PWfbwz5gcq3XBsVubdS2OdS3On9u6UlUL95Ik/cjyIxAkqXPHdNAv9DEKSU5Icktbfn+SzUPLrm7tjyd51yrX9S+TfC3JviR3JXnL0LJXk+xtjxW9QT1CXe9LMj20/386tGx7kifaY/sq13XtUE3fSPLC0LJxHq8bkhxJ8uhRlifJJ1rd+5KcPbRsnMdrobp+vtWzL8lXkrxtaNnTSR5px2tqles6P8mLQ/9e/2Zo2dg+EmWEun55qKZH2zl1Sls2luOVZFOSe5LsT/JYkg/N0Wf1zq+qOiYfDG7ifhN4K/Aa4GHgjFl9/jnwu236cuCWNn1G638CcHrbznGrWNc7gB9v0/9spq42/9IaHq/3Ab8zx7qnAE+255Pb9MmrVdes/v+Cwc37sR6vtu2/C5wNPHqU5ZcAX2TwvpBzgfvHfbxGrOvtM/tj8DEj9w8texo4dY2O1/nAF5Z7Dqx0XbP6/gPg7nEfL2A9cHabfj3wjTn+P67a+XUsX9GP8jEK24Ddbfo24MIkae03V9XLVfUUcKBtb1Xqqqp7qup7bfY+Bu8jGLflfOzEu4A7q+q5qnoeuBO4aI3qugK4aYX2Pa+q+hLw3DxdtgE31sB9wElJ1jPe47VgXVX1lbZfWL3za5TjdTRj/UiURda1KudXVR2uqofa9HeB/fzZTwdYtfPrWA76UT5G4f/3qapXgBeBN4647jjrGraDwW/tGScmmUpyX5JLV6imxdT1D9ufibclmXlT2zFxvNoQ1+nA3UPN4zpeozha7cfSR3zMPr8K+IMkD2bw7vPV9reTPJzki0nObG3HxPFK8uMMAvOzQ81jP14ZDCmfBdw/a9GqnV9je3nlCljwYxTm6TPKuks18raT/GNgEvh7Q81vrqpDSd4K3J3kkar65irV9V+Bm6rq5SQfYPDX0AUjrjvOumZcDtxWVa8OtY3reI1iLc6vkSV5B4Og/ztDzee143UacGeSr7cr3tXwEPCWqnopySXAfwG2cIwcLwbDNv+zqoav/sd6vJK8jsEvlg9X1XdmL55jlbGcX8fyFf2CH6Mw3CfJOuANDP6EG2XdcdZFkncCHwF+tqpenmmvqkPt+UngXga/6Velrqr69lAtnwT+xqjrjrOuIZcz68/qMR6vURyt9nEer5Ek+evAp4BtVfXtmfah43UE+DwrN2S5oKr6TlW91KbvAI5PcirHwPFq5ju/Vvx4JTmeQch/pqo+N0eX1Tu/VvomxEo9GPy18SSDP+VnbuCcOavPlfzwzdhb2/SZ/PDN2CdZuZuxo9R1FoObT1tmtZ8MnNCmTwWeYIVuSo1Y1/qh6fcA99UPbv481eo7uU2fslp1tX5/lcGNsazG8Rrax2aOfnPx3fzwzbIHxn28RqzrzQzuO719VvtrgdcPTX8FuGgV6/pLM/9+DALzW+3YjXQOjKuutnzmIvC1q3G82s99I/Db8/RZtfNrxQ70OB4M7kp/g0FofqS1/VsGV8kAJwK/3076B4C3Dq37kbbe48DFq1zXHwLPAnvbY09rfzvwSDvRHwF2rHJd/w54rO3/HuCnhtb9J+04HgDev5p1tfmPAh+btd64j9dNwGHg/zK4itoBfAD4QFseBl+g8822/8lVOl4L1fUp4Pmh82uqtb+1HauH27/zR1a5rg8OnV/3MfSLaK5zYLXqan3ex+AFGsPrje14MRhOK2Df0L/TJWt1fvnOWEnq3LE8Ri9JWgEGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9Jnft/IuVHUiGAnRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da3de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(newsgroups_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n",
    "\n",
    "Now that we know the dataset is ok we would like to clean the text. In NLP there are few typical cleaning techniques that are used for many tasks. However, these are definitely task dependent! For example, if you are performing name entity recognition (NER), your more than likely do not want to lowercase your text.\n",
    "\n",
    "* Lowercase\n",
    "* Remove stopwords (a, and, the, but...)\n",
    "* Removing non-letters\n",
    "* Cleaning or removing web addresses, hashtags, dates, etc\n",
    "* Lemmatization (in essence get the root of the word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(word, lemma=lemmatizer):\n",
    "#     This function will take a single word and return the lemma of it\n",
    "#     Examples:\n",
    "#         running -> run\n",
    "#         awkwardly -> awkward\n",
    "\n",
    "#     Transforming text in this way allows for better topic prediction\n",
    "#     as topics will probably contain the same root words and we don't \n",
    "#     care about the tense the topic is being discussed in.\n",
    "    \n",
    "    lemmatized = lemma.lemmatize(word, \"n\")\n",
    "    if lemmatized == word:\n",
    "        lemmatized = lemma.lemmatize(word, \"v\")\n",
    "    if lemmatized == word:\n",
    "        lemmatized = lemma.lemmatize(word, \"r\")\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "def clean_text(raw_text, remove_stop_words=True,  lemmatize_words=True):\n",
    "    # Function to clean text\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    # This is modified from https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "\n",
    "    # 1. Keep only letters or numbers        \n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", raw_text) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()  \n",
    "    \n",
    "    # 3. If we want to not remove stop words we are done - otherwise forge ahead\n",
    "    if remove_stop_words == False:\n",
    "        return words\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words, lemnitizing as we go if desired\n",
    "    if not lemmatize_words:\n",
    "        meaningful_words = [w for w in words if not w in stops]   \n",
    "    else:\n",
    "        meaningful_words = [lemmatize(w) for w in words if not w in stops]\n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result \n",
    "    return( \" \".join( meaningful_words ))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey folks--\n",
      "\n",
      "I've got a pair of Dunlop sportmax radials of my ZX-10, and they've been\n",
      "very sticky (ie no slides yet), but all this talk about the Metzelers has\n",
      "me wondering if my next set should be a Lazer comp K and a radial Metzeler\n",
      "rear...for hard sport-touring, how do the choices stack up? \n",
      "\n",
      "Without stopwords \n",
      "\n",
      "hey folks got pair dunlop sportmax radials zx 10 sticky ie slides yet talk metzelers wondering next set lazer comp k radial metzeler rear hard sport touring choices stack\n",
      "\n",
      " Without stopwords and with lemmatization \n",
      " \n",
      "hey folk get pair dunlop sportmax radial zx 10 sticky ie slide yet talk metzelers wonder next set lazer comp k radial metzeler rear hard sport tour choice stack\n"
     ]
    }
   ],
   "source": [
    "# what does the full text clean look like:\n",
    "print(newsgroups_train.data[0], '\\n')\n",
    "print(\"Without stopwords \\n\")\n",
    "print(clean_text(newsgroups_train.data[0], remove_stop_words=True, lemmatize_words=False))\n",
    "print(\"\\n Without stopwords and with lemmatization \\n \")\n",
    "print(clean_text(newsgroups_train.data[0], remove_stop_words=True, lemmatize_words=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Choose one or more algorithms\n",
    "\n",
    "Now that we have a clean dataset which we have determined is balanced, and fits our use case, we can choose one or more algorithms to experiment with. We are going to start with a very simple model as the later lessons will go into more of the deep learning techniques. So the very first model we will try is a bag of words model (BOW) with Term Frequency, Inverse Document Frequency (TF-IDF) into a logistic regression. \n",
    "\n",
    "Basically, BOW will count the number of each words occurance. TF-IDF will then weight the words that occur less frequenty in the overal corpus (aka all of our documents) so that the more infrequent words have a higher count. SKlearn has a built in function TfidfVectorizer() that we will use. One aspect to not here is that TfidfVectorizer() can remove stop words at this stage as well, but we already took care of that step in cleaning. As a side note, it definitely is not as important to remove stop words when using TF-IDF as the most frequent words are discounted naturally due to the number of times they appear in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 5000)\n",
      "[[0.         0.         0.         ... 0.         0.         0.21486039]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(analyzer = \"word\", stop_words = None, max_features = 5000)\n",
    "# Max features here is how many tokens to include in the corpus (aka number of \"words\")\n",
    "\n",
    "clean_train = [clean_text(article) for article in newsgroups_train.data]\n",
    "train_data_features = tf_idf_vectorizer.fit_transform(clean_train)\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "# At this point I like to look at the data again just to see what it looks like now\n",
    "print(train_data_features.shape)\n",
    "print(train_data_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets use a very simple model as well - that of logistic regression\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(train_data_features, newsgroups_train.target)\n",
    "\n",
    "# model is trained so we test - make sure when you fit the vectorizer you only transform\n",
    "# not fit_transform as we don't want to retrain the vectorizer\n",
    "\n",
    "clean_test = [clean_text(article) for article in newsgroups_test.data]\n",
    "test_data_features = tf_idf_vectorizer.transform(clean_test)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "predictions = logreg.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze algorithm and choose one for production\n",
    "\n",
    "There are a number of ways to analyze the algorithm once it is trained. One method that I often use is a classification report. In this report you get the precision, recall, and f1-score for each of the classes. According to Wikipedia https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg the precision answers the question \"How many selected items are relevant\" while recall answers \"How many relevant items are selected\". \n",
    "\n",
    "![alt text](Precisionrecall.svg)\n",
    "\n",
    "The F1 Score is the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the classifier was able to have the best acuracy on the space articles compared to autos and mortocycles as those two classes are much closer together.\n",
    "\n",
    "Splitting the data into a training and a test set helps to ensure that we aren't overfitting, but it is informative to see how different the classifier is able to predict the training set, as opposed to the test set that it didn't see. And indeed if we look at the table below the performance is higher with the training set. It isn't a lot of overfitting, but could be improved. The image from http://cs231n.github.io/neural-networks-3/ is a good example of how to judge overfitting, particularly with deep learning models.\n",
    "\n",
    "![alt text](accuracies.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      rec.autos       0.85      0.81      0.83       396\n",
      "rec.motorcycles       0.79      0.83      0.81       398\n",
      "      sci.space       0.90      0.89      0.89       394\n",
      "\n",
      "    avg / total       0.85      0.85      0.85      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(newsgroups_test.target, predictions, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      rec.autos       0.97      0.92      0.94       594\n",
      "rec.motorcycles       0.90      0.97      0.94       598\n",
      "      sci.space       0.99      0.97      0.98       593\n",
      "\n",
      "    avg / total       0.95      0.95      0.95      1785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions = logreg.predict(train_data_features)\n",
    "print(classification_report(newsgroups_train.target, train_predictions, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the classifier - which words is it relying on most heavily?\n",
    "\n",
    "Another aspect that may be important with assessing and choosing an algorithm, is to gain an intuition around why a certain classification was chosen. For deep learning models, attention layers are being utilized to see the top words a classifier relied on to make its decision. A similar method is used in machine learning. Explainability for NLP is an active topic of research, but they are getting more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos: wagon gt oil price toyota drive ford dealer auto car\n",
      "rec.motorcycles: bmw drink rider dog rid helmet ride dod motorcycle bike\n",
      "sci.space: program satellite fund rocket earth moon nasa orbit launch space\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(logreg, tf_idf_vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it with your own text\n",
    "\n",
    "One of the useful (and fun) things to do now if to see how the classifier will parse new text that it hasn't seen. So write a sentence and see what happens. You can also go back and do all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_input = \"I always loved watching the stars, and whenever I have the change I watch for satellites overhead :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text most fits in sci.space with a probability of 22.281605\n"
     ]
    }
   ],
   "source": [
    "clean_input = [clean_text(text_input)]\n",
    "input_data_features = tf_idf_vectorizer.transform(clean_input)\n",
    "input_data_features = input_data_features.toarray()\n",
    "\n",
    "input_prediction = logreg.predict(input_data_features)\n",
    "prediction_percentage = max(logreg.predict_proba(input_data_features))*100\n",
    "print(\"This text most fits in %s with a probability of %f\" \n",
    "      %(newsgroups_train.target_names[input_prediction[0]],prediction_percentage[0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Complete!\n",
    "\n",
    "This is the bare bones of an end-to-end analysis we can save the models. From here we can experiment with using a CountVectorizer() instead of the TfidfVectorizer(), using a different algorithm like an boosted tree, an LSTM, or a CNN. We can also play around with how we cleaned the data. Did we really want to remove stop words, or how important was lemmitization? These are all things we could experiment with and see how the results change.\n",
    "\n",
    "This notebook approached many of the aspects necessary to ensure that the algorithm being created is ethical. The folks over at DrivenData have create the checklist below that can act as a guide as you go through your project. For more information on how to install and utilize this checklist goto: http://deon.drivendata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ethics Checklist\n",
    "\n",
    "## A. Data Collection\n",
    " - [ ] **A.1 Informed consent**: If there are human subjects, have those subjects have given informed consent, where users clearly understand what they are consenting to and there was a mechanism in place for gathering consent?\n",
    " - [ ] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [ ] **A.3 Limit PII exposure**: Have we considered ways to to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "## B. Data Storage\n",
    " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "## C. Analysis\n",
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [ ] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [ ] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "## D. Modeling\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [ ] **D.5 Communicate bias**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "## E. Deployment\n",
    " - [ ] **E.1 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.2 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [ ] **E.3 Concept drift**: Do we test and monitor for concept drift to ensure the model remains fair over time?\n",
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "*Data Science Ethics Checklist generated with [deon](http://deon.drivendata.org).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
